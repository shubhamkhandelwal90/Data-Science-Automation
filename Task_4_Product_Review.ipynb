{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path= 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "\n",
    "driver= webdriver.Chrome(path)\n",
    "\n",
    "data= {\"product_name\":list(),\"product_url\":list(),\"status\":list(),\"stars\":list()}\n",
    "\n",
    "def scrapper(url):\n",
    "    base_url='https://yoshops.com'\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    html= driver.page_source\n",
    "    soup= bs(html,'html.parser')\n",
    "    products= soup.find_all(\"div\",{\"class\":\"product\"})\n",
    "    for i in range(len(products)):\n",
    "        obj= products[i].find(\"div\",{\"class\":\"single-product-review\"}).span\n",
    "        if obj is None:\n",
    "            data[\"product_name\"].append(products[i].a.span.text.strip())\n",
    "            data[\"product_url\"].append(base_url + str(products[i].a['href']))\n",
    "            data['status'].append(\"Not Reviewed\")\n",
    "            data['stars'].append(\"0 Star\")\n",
    "        else:\n",
    "            data[\"product_name\"].append(products[i].a.span.text.strip())\n",
    "            data[\"product_url\"].append(base_url + str(products[i].a['href']))\n",
    "            data['status'].append(\"Reviewed\")\n",
    "            data['stars'].append(obj.text.strip())\n",
    "def all_pages():\n",
    "    url = \"https://yoshops.com/products?page=\"\n",
    "    allpages = [url + str(i) for i in range(0, 12)]\n",
    "    return allpages\n",
    "\n",
    "def get_categories():\n",
    "    driver.get(\"https://yoshops.com/t/laptops\")\n",
    "    html = driver.page_source\n",
    "    soup = bs(html, 'html.parser')\n",
    "    cet = soup.find_all('div', {\"class\": \"categories\"})\n",
    "    cet_anchores = cet[0].find_all('a')\n",
    "    cate_dict = {}\n",
    "    base_url = 'https://yoshops.com'\n",
    "    for a in cet_anchores:\n",
    "        cate_dict[a.text.strip()] = base_url + str(a['href'])\n",
    "    return cate_dict\n",
    "\n",
    "\n",
    "def for_next_page():\n",
    "    try:\n",
    "        pages = driver.find_element_by_class_name('pagination')\n",
    "        an = pages.find_elements_by_tag_name('a')\n",
    "        li = []\n",
    "        for a in an:\n",
    "            li.append(a.get_attribute('href'))\n",
    "        for page_url in li[2:-1]:\n",
    "            scrapper(page_url)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "def scrapper_for_not_reviewed(url):\n",
    "    base_url='https://yoshops.com'\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    html= driver.page_source\n",
    "    soup= bs(html,'html.parser')\n",
    "    products= soup.find_all(\"div\",{\"class\":\"product\"})\n",
    "    for i in range(len(products)):\n",
    "        obj= products[i].find(\"div\",{\"class\":\"single-product-review\"}).span\n",
    "        if obj is None:\n",
    "            data[\"product_name\"].append(products[i].a.span.text.strip())\n",
    "            data[\"product_url\"].append(base_url + str(products[i].a['href']))\n",
    "            data['status'].append(\"Not Reviewed\")\n",
    "            data['stars'].append(\"0 Star\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def scrapper_for_reviewed(url):\n",
    "    base_url='https://yoshops.com'\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    html= driver.page_source\n",
    "    soup= bs(html,'html.parser')\n",
    "    products= soup.find_all(\"div\",{\"class\":\"product\"})\n",
    "    for i in range(len(products)):\n",
    "        obj= products[i].find(\"div\",{\"class\":\"single-product-review\"}).span\n",
    "        if obj is None:\n",
    "            pass\n",
    "        else:\n",
    "            data[\"product_name\"].append(products[i].a.span.text.strip())\n",
    "            data[\"product_url\"].append(base_url + str(products[i].a['href']))\n",
    "            data['status'].append(\"Reviewed\")\n",
    "            data['stars'].append(obj.text.strip())\n",
    "\n",
    "def save_data(data,filename):\n",
    "    df= pandas.DataFrame(data)\n",
    "    df.to_csv(filename,index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    task = input(\"Enter 1 for all products : \"\n",
    "                 \"\\nEnter 2 for category wise products :\"\n",
    "                 \"\\nEnter 3 for only reviewed products and not reviewed products :\\n\")\n",
    "    if task == '1':\n",
    "        pages= all_pages()\n",
    "        for page in pages:\n",
    "            scrapper(page)\n",
    "        save_data(data,filename=\"All_Products_Review.csv\")\n",
    "        print(\"Successfull...\")\n",
    "\n",
    "    elif task == '2':\n",
    "        cat= get_categories()\n",
    "        for key in cat.keys():\n",
    "            print(key)\n",
    "        key= input(\"Enter category: \")\n",
    "        link= cat[key]\n",
    "        scrapper(link)\n",
    "        for_next_page()\n",
    "        save_data(data,filename=key + '.csv')\n",
    "\n",
    "    elif task == '3':\n",
    "        var= input(\"Enter 1 for only Reviewed Products: \\n\"\n",
    "                   \"Enter 2 for only Not Reviewed Products: \\n\")\n",
    "        if var=='1':\n",
    "            scrapper_for_reviewed(page)\n",
    "            save_data(data,filename=\"Reviewed_Products.csv\")\n",
    "            print(\"Successfull...\")\n",
    "            \n",
    "        elif var== '2':\n",
    "            scrapper_for_not_reviewed(page)\n",
    "            save_data(data, filename=\"Not_Reviewed_Products.csv\")\n",
    "            print(\"Successfull...\")\n",
    "        else:\n",
    "            print(\"Not Successfull...\")\n",
    "            print(\"Enter correct input\")\n",
    "            \n",
    "\n",
    "    else:\n",
    "        print(\"Enter correct input\")\n",
    "        task = input(\"Enter 1 for all products : \"\n",
    "                 \"\\nEnter 2 for category wise products :\"\n",
    "                 \"\\nEnter 3 for only reviewed products and not reviewed products :\\n\")\n",
    "        if task == '1':\n",
    "            pages= all_pages()\n",
    "            for page in pages:\n",
    "                scrapper(page)\n",
    "            save_data(data,filename=\"All_Products_Review.csv\")\n",
    "            print(\"Successfull...\")\n",
    "\n",
    "        elif task == '2':\n",
    "            cat= get_categories()\n",
    "            for key in cat.keys():\n",
    "                print(key)\n",
    "            key= input(\"Enter category: \")\n",
    "            link= cat[key]\n",
    "            scrapper(link)\n",
    "            for_next_page()\n",
    "            save_data(data,filename=key + '.csv')\n",
    "\n",
    "        elif task == '3':\n",
    "            var= input(\"Enter 1 for only Reviewed Products: \\n\"\n",
    "                       \"Enter 2 for only Not Reviewed Products: \\n\")\n",
    "            if var=='1':\n",
    "                scrapper_for_reviewed(page)\n",
    "                save_data(data,filename=\"Reviewed_Products.csv\")\n",
    "                print(\"Successfull...\")\n",
    "\n",
    "            elif var== '2':\n",
    "                scrapper_for_not_reviewed(page)\n",
    "                save_data(data, filename=\"Not_Reviewed_Products.csv\")\n",
    "                print(\"Successfull...\")\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
